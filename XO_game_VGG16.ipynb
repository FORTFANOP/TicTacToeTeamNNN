{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vi4RgZUIJP-S"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = [28, 28]"
      ],
      "metadata": {
        "id": "5rJTABuKJZ-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Give dataset path\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/TicTacToe Techne NNN/dataset/Train/TrainTestData/Train_Folder'\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/TicTacToe Techne NNN/dataset/Train/TrainTestData/Test_Folder'"
      ],
      "metadata": {
        "id": "zUJtx--1KXmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Define function to load images and preprocess them\n",
        "# VGG 16 accepts images of size (32, 32) so I need to resize the (28, 28) imgs to (32x32)\n",
        "\n",
        "def load_and_preprocess_images(folder_path, target_size=(32, 32)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = sorted(os.listdir(folder_path))\n",
        "    for class_index, class_name in enumerate(class_names):\n",
        "        class_folder = os.path.join(folder_path, class_name)\n",
        "        for image_name in os.listdir(class_folder):\n",
        "            image_path = os.path.join(class_folder, image_name)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "            if image is not None:\n",
        "                image = cv2.resize(image, target_size)  # Resize to (32, 32)\n",
        "                image = np.stack([image] * 3, axis=-1)  # Convert to RGB by stacking channels\n",
        "                images.append(image)\n",
        "                labels.append(class_index)\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    return images, labels, class_names\n",
        "\n",
        "# Load and preprocess train and test images\n",
        "train_folder = '/content/drive/MyDrive/Colab Notebooks/TicTacToe Techne NNN/dataset/Train/TrainTestData/Train_Folder'\n",
        "test_folder = '/content/drive/MyDrive/Colab Notebooks/TicTacToe Techne NNN/dataset/Train/TrainTestData/Test_Folder'\n",
        "\n",
        "X_train, y_train, class_names = load_and_preprocess_images(train_folder)\n",
        "X_test, y_test, _ = load_and_preprocess_images(test_folder)\n",
        "\n",
        "# Normalize the data\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(class_names))\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(class_names))\n",
        "\n",
        "# Load the VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Add custom layers on top of VGG16\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(len(class_names), activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Freeze the base model layers (optional)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/TicTacToe Techne NNN/dataset/XO_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "\n",
        "# Data augmentation for the training data\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=45,\n",
        "    width_shift_range=0,\n",
        "    height_shift_range=0,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.1  # Split training data for validation\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "train_generator = datagen.flow(X_train, y_train, batch_size=32, subset='training')\n",
        "validation_generator = datagen.flow(X_train, y_train, batch_size=32, subset='validation')\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint, early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkpynNGhWWmU",
        "outputId": "4a04cd88-014b-481d-fba3-efb3a42c6f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.7706 - loss: 0.4577\n",
            "Epoch 1: val_accuracy improved from -inf to 0.91667, saving model to /content/drive/MyDrive/Colab Notebooks/TicTacToe Techne NNN/dataset/XO_model.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 442ms/step - accuracy: 0.7719 - loss: 0.4556 - val_accuracy: 0.9167 - val_loss: 0.2125\n",
            "Epoch 2/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.9117 - loss: 0.1853\n",
            "Epoch 2: val_accuracy improved from 0.91667 to 0.97059, saving model to /content/drive/MyDrive/Colab Notebooks/TicTacToe Techne NNN/dataset/XO_model.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 469ms/step - accuracy: 0.9119 - loss: 0.1850 - val_accuracy: 0.9706 - val_loss: 0.1369\n",
            "Epoch 3/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.9319 - loss: 0.1619\n",
            "Epoch 3: val_accuracy did not improve from 0.97059\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 401ms/step - accuracy: 0.9321 - loss: 0.1616 - val_accuracy: 0.9412 - val_loss: 0.1647\n",
            "Epoch 4/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.9553 - loss: 0.1236\n",
            "Epoch 4: val_accuracy did not improve from 0.97059\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 437ms/step - accuracy: 0.9553 - loss: 0.1235 - val_accuracy: 0.9608 - val_loss: 0.1199\n",
            "Epoch 5/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.9737 - loss: 0.0759\n",
            "Epoch 5: val_accuracy did not improve from 0.97059\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 406ms/step - accuracy: 0.9737 - loss: 0.0760 - val_accuracy: 0.9706 - val_loss: 0.0796\n",
            "Epoch 6/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.9692 - loss: 0.0849\n",
            "Epoch 6: val_accuracy improved from 0.97059 to 0.97549, saving model to /content/drive/MyDrive/Colab Notebooks/TicTacToe Techne NNN/dataset/XO_model.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 413ms/step - accuracy: 0.9692 - loss: 0.0848 - val_accuracy: 0.9755 - val_loss: 0.0619\n",
            "Epoch 7/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.9799 - loss: 0.0720\n",
            "Epoch 7: val_accuracy did not improve from 0.97549\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 406ms/step - accuracy: 0.9797 - loss: 0.0722 - val_accuracy: 0.9412 - val_loss: 0.1544\n",
            "Epoch 8/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.9794 - loss: 0.0639\n",
            "Epoch 8: val_accuracy did not improve from 0.97549\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 432ms/step - accuracy: 0.9793 - loss: 0.0639 - val_accuracy: 0.9657 - val_loss: 0.0773\n",
            "Epoch 9/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - accuracy: 0.9805 - loss: 0.0709\n",
            "Epoch 9: val_accuracy did not improve from 0.97549\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 475ms/step - accuracy: 0.9805 - loss: 0.0708 - val_accuracy: 0.9510 - val_loss: 0.1186\n",
            "Epoch 10/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.9773 - loss: 0.0601\n",
            "Epoch 10: val_accuracy did not improve from 0.97549\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 407ms/step - accuracy: 0.9774 - loss: 0.0601 - val_accuracy: 0.9363 - val_loss: 0.1708\n",
            "Epoch 11/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - accuracy: 0.9657 - loss: 0.0822\n",
            "Epoch 11: val_accuracy improved from 0.97549 to 0.99020, saving model to /content/drive/MyDrive/Colab Notebooks/TicTacToe Techne NNN/dataset/XO_model.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 479ms/step - accuracy: 0.9659 - loss: 0.0820 - val_accuracy: 0.9902 - val_loss: 0.0300\n",
            "Epoch 12/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.9734 - loss: 0.0614\n",
            "Epoch 12: val_accuracy did not improve from 0.99020\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 458ms/step - accuracy: 0.9735 - loss: 0.0613 - val_accuracy: 0.9902 - val_loss: 0.0340\n",
            "Epoch 13/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.9786 - loss: 0.0527\n",
            "Epoch 13: val_accuracy did not improve from 0.99020\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 399ms/step - accuracy: 0.9787 - loss: 0.0526 - val_accuracy: 0.9510 - val_loss: 0.0917\n",
            "Epoch 14/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.9846 - loss: 0.0420\n",
            "Epoch 14: val_accuracy did not improve from 0.99020\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 396ms/step - accuracy: 0.9846 - loss: 0.0421 - val_accuracy: 0.9755 - val_loss: 0.0784\n",
            "Epoch 15/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.9788 - loss: 0.0501\n",
            "Epoch 15: val_accuracy improved from 0.99020 to 0.99510, saving model to /content/drive/MyDrive/Colab Notebooks/TicTacToe Techne NNN/dataset/XO_model.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 411ms/step - accuracy: 0.9788 - loss: 0.0501 - val_accuracy: 0.9951 - val_loss: 0.0155\n",
            "Epoch 16/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - accuracy: 0.9821 - loss: 0.0495\n",
            "Epoch 16: val_accuracy did not improve from 0.99510\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 485ms/step - accuracy: 0.9821 - loss: 0.0494 - val_accuracy: 0.9951 - val_loss: 0.0286\n",
            "Epoch 17/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.9773 - loss: 0.0541\n",
            "Epoch 17: val_accuracy did not improve from 0.99510\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 397ms/step - accuracy: 0.9773 - loss: 0.0540 - val_accuracy: 0.9902 - val_loss: 0.0277\n",
            "Epoch 18/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.9896 - loss: 0.0297\n",
            "Epoch 18: val_accuracy did not improve from 0.99510\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 439ms/step - accuracy: 0.9895 - loss: 0.0298 - val_accuracy: 0.9804 - val_loss: 0.0436\n",
            "Epoch 19/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.9866 - loss: 0.0404\n",
            "Epoch 19: val_accuracy did not improve from 0.99510\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 450ms/step - accuracy: 0.9866 - loss: 0.0404 - val_accuracy: 0.9706 - val_loss: 0.0768\n",
            "Epoch 20/20\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.9861 - loss: 0.0453\n",
            "Epoch 20: val_accuracy did not improve from 0.99510\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 398ms/step - accuracy: 0.9861 - loss: 0.0451 - val_accuracy: 0.9902 - val_loss: 0.0286\n",
            "Epoch 20: early stopping\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 312ms/step - accuracy: 0.9861 - loss: 0.0292\n",
            "Test accuracy: 0.9882\n"
          ]
        }
      ]
    }
  ]
}